{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e8b129",
   "metadata": {},
   "source": [
    "# comparison between relational and non relational databases:\n",
    "## Relational Database :\n",
    "-Tables are structured related to each other\n",
    "\n",
    "-Each specific type of domain data is strored\n",
    " it's own table\n",
    "\n",
    "## Non-Relational Database :\n",
    "-There is no relation at all between tables\n",
    "\n",
    "-Mostly key+value pair : like jSon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b16b7",
   "metadata": {},
   "source": [
    "# Data Science Tools:\n",
    "#### Tensorflow\n",
    "Focused on deep learning, launched by Google, Tensorflow has 153k stars on github.\n",
    "####  PyTorch\n",
    "Open source, built in Python, starred by ±45k in github.\n",
    "#### RapidMiner\n",
    "Rapidminer is built on three major components. RapidMiner studio is the Visual Workflow Designer for Data Science Teams. It is a platform with Code-optional with guided analytics With more than 1500 function, it allows users to automate predefined connections, built-in templates, and repeatable workflows. RapidMiner serves Share and collaborates on every step and aspect of the data mining process. It allows to optimize with the advanced queuing mechanism: RapidMiner Server can slice out resources and dedicate to teams, use cases or projects. The platform makes it possible to get visibility into data science teamwork and governance. RapidMiner Radoop removes the complexity of data prep and machine learning on Hadoop and Spark. The platform is used in many industries with different types of solutions.\n",
    "#### DataRobot\n",
    "DataRobot offers a machine learning platform for data scientists of all skill levels to build and deploy accurate predictive models in a fraction of the time it used to take. The technology addresses the critical shortage of data scientists by changing the speed and economics of predictive analytics.\n",
    "#### Alteryx\n",
    "offers a quick-to-implement, end-to-end analytics platform that empowers business analysts and data scientists alike to break data barriers and deliver game-changing insights that are solving big business problems. The Alteryx platform is self-serve, click, drag-and-drop for hundreds of thousands of people in leading enterprises all over the world.\n",
    "#### Qubole\n",
    "Qubole is passionate about making data-driven insights easily accessible to anyone. \n",
    "#### Paxata\n",
    "Paxata is the pioneer in intelligently empowering all business consumers to transform raw data into ready information, instantly and automatically, with an intelligent, self-service data preparation application built on a scalable, enterprise-grade platform powered by machine learning. \n",
    "#### Trifacta\n",
    "Trifacta’s mission is to create radical productivity for people who analyze data. They are deeply focused on solving the biggest bottleneck in the data lifecycle, data wrangling, by making it more intuitive and efficient for anyone who works with data. \n",
    "#### Lumen Data\n",
    "LumenData is a leading provider of Enterprise Information Management solutions with deep expertise in implementing Data persistence layers for data mastering, prediction systems, and data lakes as well as Data Strategy, Data Quality, Data Governance, and Predictive Analytics. \n",
    "#### Web Crawlers\n",
    "Web crawlers are a type of software which collect structured web data which can be leveraged in numerous data science projects such as real-time analytics, training predictive machine learning models, improving natural language processing capabilities, etc. Some of the popular data science projects based on web crawling are the language models GPT-3 and Google’s LaMDA.\n",
    "\n",
    "https://research.aimultiple.com/data-science-tools/\n",
    "\n",
    "#### Dataiku Data Science Studio (DSS)\n",
    "Dataiku offers an advanced analytics solution that allows organizations to create their own data tools. The company’s flagship product features a team-based user interface for both data analysts and data scientists.\n",
    "####  Databricks Unified Analytics Platform\n",
    "Databricks offers a cloud and Apache Spark-based unified analytics platform that combines data engineering and data science functionality. The product leverages an array of open-source languages and includes proprietary features for operationalization, performance, and real-time enablement on Amazon Web Services. A Data Science Workspace enables users to explore data and build models collaboratively. It also provides one-click access to preconfigured ML environments for augmented machine learning with popular frameworks. \n",
    "#### Domino Data Science Platform\n",
    "Domino Data Lab offers an enterprise data science platform that allows data scientists to build and run predictive models. The product helps organizations with the development and delivery of these models via infrastructure automation and collaboration. Domino provides users access to a data science Workbench that provides open source and commercial tools for batch experiments, as well as Model Delivery so they can publish APIs and web apps or schedule reports.\n",
    "#### Google Cloud AI Platform\n",
    "Google Cloud AI offers one of the largest machine learning stacks in the space and offers an expanding list of products for a variety of use cases. The product is fully managed and offers excellent governance with interpretable models. Key features include a built-in Data Labeling Service, AutoML, model validation via AI Explanations, a What-If Tool which helps you understand model outputs, cloud model deployment with Prediction, and MLOps via the Pipeline tool. \n",
    "#### H2O Driverless AI\n",
    " H2O.ai offers a number of AI and data science products, headlined by its commercial platform H2O Driverless AI. Driverless AI is a fully open-source, distributed in-memory machine learning platform with linear scalability. H2O supports widely used statistical and machine learning algorithms including gradient boosted machines, generalized linear models, deep learning and more. H2O has also developed AutoML functionality that automatically runs through all the algorithms to produce a leaderboard of the best models. \n",
    "#### IBM Watson Studio\n",
    "IBM Watson Studio enables users to build, run, and manage AI models at scale across any cloud. The product is a part of IBM Cloud Pak for Data, the company’s main data and AI platform. The solution lets you automate AI lifecycle management, govern and secure open-source notebooks, prepare and build models visually, deploy and run models through one-click integration, and manage and monitor models with explainable AI. IBM Watson Studio offers a flexible architecture that allows users to utilize open-source frameworks like PyTorch, TensorFlow, and scikit-learn. \n",
    "#### KNIME Analytics Platform\n",
    " KNIME Analytics is an open-source platform for creating data science. It enables the creation of visual workflows via a drag-and-drop-style graphical interface that requires no coding. Users can choose from more than 2000 nodes to build workflows, model each step of analysis, control the flow of data, and ensure work is current. KNIME can blend data from any source and shape data to derive statistics, clean data, and extract and select features. The product leverages AI and machine learning and can visualize data with classic and advanced charts.\n",
    "#### MATLAB\n",
    "MathWorks MATLAB combines a desktop environment tuned for iterative analysis and design processes with a programming language that expresses matrix and array mathematics directly. It includes the Live Editor for creating scripts that combine code, output, and formatted text in an executable notebook. MATLAB toolboxes are professionally developed, tested, and fully documented. MATLAB apps let you see how different algorithms work with your data as well.\n",
    "#### Azure Machine Learning\n",
    " The Azure Machine Learning service lets developers and data scientists build, train, and deploy machine learning models. The product features productivity for all skill levels via a code-first and drag-and-drop designer, and automated machine learning. It also features expansive MLops capabilities that integrate with existing DevOps processes. The service touts responsible machine learning so users can understand models with interpretability and fairness, as well as protect data with differential privacy and confidential computing. Azure Machine Learning supports open-source frameworks and languages like MLflow, Kubeflow, ONNX, PyTorch, TensorFlow, Python, and R. \n",
    "#### SAS Visual Data Mining and Machine Learning\n",
    "SAS offers a suite of advanced analytics and data science products which is headlined by SASVisual Data Mining and Machine Learning. The product provides access to data in any format and from any source, as well as automated data preparation and data lineage and model management. SAS Visual Data Mining and Machine Learning automatically generates insights for common variables across models. It also features natural language generation for creating project summaries. The companion SAS Model Manager enables users to register SAS and open-source models within projects or as standalone models.\n",
    "#### TIBCO Data Science\n",
    "TIBCO offers an expansive product portfolio for modern BI, descriptive and predictive analytics, and streaming analytics and data science. TIBCO Data Science lets users do data preparation, model building, deployment and monitoring. It also features AutoML, drag-and-drop workflows, and embedded Jupyter Notebooks for sharing reusable modules. Users can run workflows on TIBCO’s Spotfire Analytics and leverage TensorFlow, SageMaker, Rekognition and Cognitive Services to orchestrate open source.\n",
    "\n",
    "\n",
    "https://solutionsreview.com/business-intelligence/the-best-data-science-and-machine-learning-platforms/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47876ffa",
   "metadata": {},
   "source": [
    " # What are examples of data science competition platforms?\n",
    "#### AIcrowd: \n",
    "AIcrowd is a platform that runs AI, machine learning, and other data science challenges.\n",
    "#### bitgrit\n",
    "bitgrit is a platform that enables data scientists to interact with a global network and community.\n",
    "#### Coda Lab\n",
    "CodaLab is an open-source platform that provides an ecosystem for conducting computational research in a more efficient, reproducible, and collaborative manner. There are two services **CodaLab offers:**\n",
    "\n",
    "1-allowing businesses to capture complex research pipelines in a reproducible way\n",
    "\n",
    "2-enabling data scientist to enter a competition to solve problems that companies host\n",
    "#### CrowdANALYTIX\n",
    "CrowdANALYTIX offers cloud crowdsourced analytics services that convert business challenges into analytics competitions and address solutions that require predictive analytics, descriptive analytics, estimations, and business hypothesis validation.\n",
    "####  DrivenData\n",
    "DrivenData differentiates from other data science competition platforms with their mission. They focus on social challenges of mission-driven organizations that will eventually impact the world.\n",
    "#### InnoCentive\n",
    "InnoCentive is a cloud-based innovation management platform that connects commercial enterprises, public sector agencies and nonprofit organizations with 400000+ to innovate faster and better. \n",
    "####  Kaggle\n",
    "Kaggle offers both public and private data science competitions and on-demand consulting by a global data science and developer talent pool.\n",
    "\n",
    "https://research.aimultiple.com/data-science-competition/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3a815",
   "metadata": {},
   "source": [
    "# how to append in dataframe:\n",
    "## Method1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef26200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T05:21:12.643670Z",
     "start_time": "2022-03-05T05:21:10.785684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dat1</th>\n",
       "      <th>dat2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dat1  dat2\n",
       "0     9     7\n",
       "1     5     6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "dat1 = pd.DataFrame({'dat1': [9,5]})\n",
    "dat2 = pd.DataFrame({'dat2': [7,6]})\n",
    "dat1.join(dat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb41e105",
   "metadata": {},
   "source": [
    "## Method2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e29e7776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T05:23:02.154640Z",
     "start_time": "2022-03-05T05:23:02.128657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0  1  2\n",
       "1  3  4\n",
       "0  5  6\n",
       "1  7  8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
    "df\n",
    "df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
    "df.append(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e9d470",
   "metadata": {},
   "source": [
    "# how to read random rows from your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70898eb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T05:25:32.079455Z",
     "start_time": "2022-03-05T05:25:32.063453Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-f521edf1bfb3>:2: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df = pd.DataFrame(pd.np.random.random(100))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = pd.DataFrame(pd.np.random.random(100))\n",
    "\n",
    "# Randomly sample 70% of your dataframe\n",
    "df_percent = df.sample(frac=0.7)\n",
    "\n",
    "# Randomly sample 7 elements from your dataframe\n",
    "df_elements = df.sample(n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda2daaf",
   "metadata": {},
   "source": [
    "# how to save and append on the csv file with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c78e8c89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T05:26:12.473307Z",
     "start_time": "2022-03-05T05:26:12.448307Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('my_csv.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e799a59e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T05:26:27.212187Z",
     "start_time": "2022-03-05T05:26:27.184205Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-15625769b538>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mli\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mli\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \"\"\"\n\u001b[1;32m--> 285\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No objects to concatenate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "path = r'C:\\DRO\\DCL_rawdata_files' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ea3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
